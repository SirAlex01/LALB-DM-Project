import csv
import unicodedata
import re

# Allowed characters
allowed_chars = set("fhŒ±Œ≤Œ≥Œ¥ŒµŒ∂Œ∑Œ∏ŒπŒ∫ŒªŒºŒΩŒæŒøœÄœÅœÇœÉœÑœÖœÜœáœàœâ|")

# Comprehensive correction dictionary
correction_dict = {
    # Greek uppercase to lowercase
    'Œë': 'Œ±', 'Œí': 'Œ≤', 'Œì': 'Œ≥', 'Œî': 'Œ¥', 'Œï': 'Œµ', 'Œñ': 'Œ∂', 'Œó': 'Œ∑', 'Œò': 'Œ∏',
    'Œô': 'Œπ', 'Œö': 'Œ∫', 'Œõ': 'Œª', 'Œú': 'Œº', 'Œù': 'ŒΩ', 'Œû': 'Œæ', 'Œü': 'Œø', 'Œ†': 'œÄ',
    'Œ°': 'œÅ', 'Œ£': 'œÉ', 'Œ§': 'œÑ', 'Œ•': 'œÖ', 'Œ¶': 'œÜ', 'Œß': 'œá', 'Œ®': 'œà', 'Œ©': 'œâ',
    
    # Common Latin uppercase that might appear
    'A': 'Œ±', 'B': 'Œ≤', 'G': 'Œ≥', 'D': 'Œ¥', 'E': 'Œµ', 'Z': 'Œ∂', 'H': 'Œ∑', 'Q': 'Œ∏',
    'I': 'Œπ', 'K': 'Œ∫', 'L': 'Œª', 'M': 'Œº', 'N': 'ŒΩ', 'X': 'Œæ', 'O': 'Œø', 'P': 'œÄ',
    'R': 'œÅ', 'S': 'œÉ', 'T': 'œÑ', 'U': 'œÖ', 'F': 'œÜ', 'C': 'œá', 'Y': 'œà', 'W': 'œâ',
    
    # Accented/diacritic vowels to plain vowels
    'Œ¨': 'Œ±', '·Ω∞': 'Œ±', '·æ∂': 'Œ±', '·ºÄ': 'Œ±', '·ºÅ': 'Œ±', '·ºÑ': 'Œ±', '·ºÖ': 'Œ±', '·ºÇ': 'Œ±', '·ºÉ': 'Œ±',
    '·ºÜ': 'Œ±', '·ºá': 'Œ±', '·æ≥': 'Œ±', '·æ¥': 'Œ±', '·æ≤': 'Œ±', '·æ∑': 'Œ±', '·æÄ': 'Œ±', '·æÅ': 'Œ±', '·æÑ': 'Œ±',
    '·æÖ': 'Œ±', '·æÇ': 'Œ±', '·æÉ': 'Œ±', '·æÜ': 'Œ±', '·æá': 'Œ±',
    
    'Œ≠': 'Œµ', '·Ω≤': 'Œµ', '·ºê': 'Œµ', '·ºë': 'Œµ', '·ºî': 'Œµ', '·ºï': 'Œµ', '·ºí': 'Œµ', '·ºì': 'Œµ',
    
    'ŒÆ': 'Œ∑', '·Ω¥': 'Œ∑', '·øÜ': 'Œ∑', '·º†': 'Œ∑', '·º°': 'Œ∑', '·º§': 'Œ∑', '·º•': 'Œ∑', '·º¢': 'Œ∑', '·º£': 'Œ∑',
    '·º¶': 'Œ∑', '·ºß': 'Œ∑', '·øÉ': 'Œ∑', '·øÑ': 'Œ∑', '·øÇ': 'Œ∑', '·øá': 'Œ∑', '·æê': 'Œ∑', '·æë': 'Œ∑', '·æî': 'Œ∑',
    '·æï': 'Œ∑', '·æí': 'Œ∑', '·æì': 'Œ∑', '·æñ': 'Œ∑', '·æó': 'Œ∑',
    
    'ŒØ': 'Œπ', '·Ω∂': 'Œπ', '·øñ': 'Œπ', '·º∞': 'Œπ', '·º±': 'Œπ', '·º¥': 'Œπ', '·ºµ': 'Œπ', '·º≤': 'Œπ', '·º≥': 'Œπ',
    '·º∂': 'Œπ', '·º∑': 'Œπ', 'œä': 'Œπ', 'Œê': 'Œπ', '·øí': 'Œπ', '·øó': 'Œπ',
    
    'œå': 'Œø', '·Ω∏': 'Œø', '·ΩÄ': 'Œø', '·ΩÅ': 'Œø', '·ΩÑ': 'Œø', '·ΩÖ': 'Œø', '·ΩÇ': 'Œø', '·ΩÉ': 'Œø',
    
    'œç': 'œÖ', '·Ω∫': 'œÖ', '·ø¶': 'œÖ', '·Ωê': 'œÖ', '·Ωë': 'œÖ', '·Ωî': 'œÖ', '·Ωï': 'œÖ', '·Ωí': 'œÖ', '·Ωì': 'œÖ',
    '·Ωñ': 'œÖ', '·Ωó': 'œÖ', 'œã': 'œÖ', 'Œ∞': 'œÖ', '·ø¢': 'œÖ', '·øß': 'œÖ', '·ø†': 'œÖ', '·ø°': 'œÖ',
    
    'œé': 'œâ', '·Ωº': 'œâ', '·ø∂': 'œâ', '·Ω†': 'œâ', '·Ω°': 'œâ', '·Ω§': 'œâ', '·Ω•': 'œâ', '·Ω¢': 'œâ', '·Ω£': 'œâ',
    '·Ω¶': 'œâ', '·Ωß': 'œâ', '·ø≥': 'œâ', '·ø¥': 'œâ', '·ø≤': 'œâ', '·ø∑': 'œâ', '·æ†': 'œâ', '·æ°': 'œâ', '·æ§': 'œâ',
    '·æ•': 'œâ', '·æ¢': 'œâ', '·æ£': 'œâ', '·æ¶': 'œâ', '·æß': 'œâ',
    
    # Rough breathing marks on consonants
    '·ø•': 'œÅ', '·ø¨': 'œÅ',
    
    # Remove spaces, hyphens, commas
    ' ': '', '-': '', ',': '',
    
    # Latin characters that might appear
    'i': 'Œπ', 'a': 'Œ±', 'o': 'Œø'
}

def normalize_greek_word(word, linear_b_key=""):
    """Apply all normalizations to a Greek word"""
    # First apply character-by-character corrections
    corrected = ''.join(correction_dict.get(char, char) for char in word)
    
    # Remove any remaining diacritics using Unicode normalization
    normalized = unicodedata.normalize('NFD', corrected)
    without_diacritics = ''.join(char for char in normalized if unicodedata.category(char) != 'Mn')
    
    # Replace trailing "qe" with "œÑŒµ" 
    if without_diacritics.endswith('qe'):
        without_diacritics = without_diacritics[:-2] + 'œÑŒµ'
    # Only replace Œ∫Œµ/Œ≥Œµ with œÑŒµ if the original Linear B key ended with "-qe"
    elif linear_b_key.endswith('-qe'):
        if without_diacritics.endswith('Œ∫Œµ'):
            without_diacritics = without_diacritics[:-2] + 'œÑŒµ'
        elif without_diacritics.endswith('Œ≥Œµ'):
            without_diacritics = without_diacritics[:-2] + 'œÑŒµ'
    
    # Replace middle œÇ with œÉ (but keep final œÇ)
    if len(without_diacritics) > 1:
        # Replace all œÇ with œÉ first, then put back final œÇ if it was there
        temp = without_diacritics.replace('œÇ', 'œÉ')
        if without_diacritics.endswith('œÇ'):
            temp = temp[:-1] + 'œÇ'
        without_diacritics = temp
    
    return without_diacritics

def check_greek_characters(path, delimiter="\t"):
    corrections_made = []
    words_with_bad_chars = 0
    still_problematic = 0
    
    with open(path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f, delimiter=delimiter)
        if "gemini" not in reader.fieldnames:
            raise ValueError("File must have a 'gemini' column")

        for row in reader:
            gemini_field = row["gemini"]
            linear_b_key = row[reader.fieldnames[0]]  # First column is the Linear B key
            
            # Check if original field has bad characters
            original_bad_chars = {ch for ch in gemini_field if ch not in allowed_chars}
            if original_bad_chars:
                words_with_bad_chars += 1
            
            # Split by | to handle multiple words
            words = gemini_field.split('|')
            corrected_words = []
            
            for word in words:
                original_word = word
                corrected_word = normalize_greek_word(word, linear_b_key)
                corrected_words.append(corrected_word)
                
                # Check if correction was needed
                if original_word != corrected_word:
                    corrections_made.append((linear_b_key, original_word, corrected_word))
            
            # Check for any remaining bad characters after correction
            corrected_field = '|'.join(corrected_words)
            bad_chars = {ch for ch in corrected_field if ch not in allowed_chars}
            if bad_chars:
                still_problematic += 1
                print(f"‚ö†Ô∏è Still problematic in key {linear_b_key}: {''.join(sorted(bad_chars))} {corrected_field}")
    
    # Show statistics
    print(f"\nüìä STATISTICS:")
    print(f"Words with bad characters needing correction: {words_with_bad_chars}")
    print(f"Total corrections made: {len(corrections_made)}")
    print(f"Words still problematic after correction: {still_problematic}")
    
    # Compliance check
    if still_problematic == 0:
        print("‚úÖ ALL WORDS NOW COMPLY WITH THE ALLOWED CHARACTER SET!")
    else:
        print(f"‚ùå {still_problematic} words still have compliance issues")
    
    # Show all corrections made
    if corrections_made:
        print("\n=== CORRECTIONS MADE ===")
        for key, before, after in corrections_made:
            if before != after:
                print(f"Key {key}: '{before}' ‚Üí '{after}'")
    else:
        print("\n‚úÖ No corrections needed!")

if __name__ == "__main__":
    check_greek_characters("cognates_translation.cog")
